<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Salientia Stuff</title><link href="https://yvanhuele.github.io/" rel="alternate"></link><link href="https://yvanhuele.github.io/feeds/all.atom.xml" rel="self"></link><id>https://yvanhuele.github.io/</id><updated>2018-03-27T11:15:00-06:00</updated><entry><title>K-Means Clustering Part 2</title><link href="https://yvanhuele.github.io/k-means-clustering-part-2.html" rel="alternate"></link><published>2018-03-27T11:15:00-06:00</published><updated>2018-03-27T11:15:00-06:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-03-27:/k-means-clustering-part-2.html</id><summary type="html">&lt;h2&gt;Initialization: Where do you start?&lt;/h2&gt;
&lt;p&gt;In &lt;a href="http://www.salientiastuff.com/k-means-clustering-part-1.html"&gt;part 1 of this series&lt;/a&gt;, we introduced K-means clustering. We ended with an overview of the algorithm which involved repeatedly updating cluster labels and cluster centroids until they settled down to a stable configuration, but we postponed the discussion of one crucial step: where …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Initialization: Where do you start?&lt;/h2&gt;
&lt;p&gt;In &lt;a href="http://www.salientiastuff.com/k-means-clustering-part-1.html"&gt;part 1 of this series&lt;/a&gt;, we introduced K-means clustering. We ended with an overview of the algorithm which involved repeatedly updating cluster labels and cluster centroids until they settled down to a stable configuration, but we postponed the discussion of one crucial step: where to start. That is the focus of this post.&lt;/p&gt;
&lt;p&gt;There are a variety of initialization methods for &lt;span class="math"&gt;\(K\)&lt;/span&gt;-means clustering. The existence of different initialization techniques points to one weakness of K-means clustering: the final clustering is very much dependent on how you start. This dependence reveals itself in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Different initializations can lead to different final clusterings &lt;strong&gt;of different quality&lt;/strong&gt;. That is, one set of clusters may be more tightly packed than the other. In more technical terms, the within cluster variation of the resulting clusters are different.&lt;/li&gt;
&lt;li&gt;Even when two initializations result in the same final clustering, &lt;strong&gt;one may require many more steps&lt;/strong&gt; to get there.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The goal of this post is to look at a few different initialization techniques and some things that can go wrong in the the K-means algorithm. Our goal is exploration, so you should be careful not to generalize too much from the examples. In particular, we'll be working with toy data sets in 2-dimensions and will not have to worry about the &lt;a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality"&gt;curse of dimensionality&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For a more thorough survey of different initialization methods, see the paper &lt;a href="https://arxiv.org/abs/1209.1960"&gt;&lt;em&gt;A Comparative Study of Efficient Initialization Methods for the K-Means Clustering Algorithm&lt;/em&gt;&lt;/a&gt; by Celebi, Kingravi, and Vela.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/yvanhuele/yvanhuele.github.io/blob/extra-blog-materials/K-Means/K-Means%20Clustering.ipynb"&gt;Jupyter notebook&lt;/a&gt; containing the code for part 1 of this series has been expanded to include the code for the second part as well.&lt;/p&gt;
&lt;h2&gt;Random Methods&lt;/h2&gt;
&lt;p&gt;We will look at the following three initialization methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Random partition&lt;/strong&gt;: Initialize the labels by randomly assigning each data point to a cluster.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random points&lt;/strong&gt;: Initialize the centroids by selecting &lt;span class="math"&gt;\(K\)&lt;/span&gt; data points uniformly at random.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class="math"&gt;\(K\)&lt;/span&gt;-means++&lt;/strong&gt;: Initialize the centroids by selecting &lt;span class="math"&gt;\(K\)&lt;/span&gt; data points sequentially following a probability distribution determined by the centroids that have already been selected.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A note about the terminology&lt;/strong&gt;: Different authors have referred to both the random partition method and the random points method as &lt;em&gt;Forgy&lt;/em&gt; initialization after Edward Forgy. Celebi et al maintain that Forgy introduced the random partition method and that the random points method was introduced by James MacQueen. We'll try to avoid mis-attribution and confusion by using the names above.&lt;/p&gt;
&lt;p&gt;The Scikit-Learn &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"&gt;KMeans&lt;/a&gt; function allows for three different initialization techniques including K-means++ (the default) and random points (simply called random). For the third initialization method, you can directly provide an array of initial cluster labels.    &lt;/p&gt;
&lt;p&gt;A key feature of these three methods is that the initialization involves some randomness. As mentioned above and as we'll see below in more detail, it is possible for different initializations to converge to different solutions. One way to deal with this problem is to run K-means several times with different random initializations (though not necessarily different initialization techniques).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The first step is random, it's true&lt;br /&gt;
Once it's taken, you just follow through&lt;br /&gt;
And times when your cluster&lt;br /&gt;
Results are lackluster&lt;br /&gt;
You're better off starting anew&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Random Partition Initialization&lt;/h2&gt;
&lt;p&gt;For the random partition initialization method, we assign each point to a cluster uniformly at random.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Random partition initialization and first steps of K-means" src="https://yvanhuele.github.io/images/k-means/random_partition_initialization.png" style="max-width:80%" /&gt;&lt;/p&gt;
&lt;p&gt;The initial centroids generated this way tend to be close together: the centroid of each cluster is an unbiased estimator of the centroid of the full data. This can be a problem if no actual data points are near the centroid of the full data. For example, the initialization below caused the number of clusters to drop.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Initialization causing the number of clusters to decrease" src="https://yvanhuele.github.io/images/k-means/bad_random_partition.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;No point is closest to the initial blue centroid. This means, that when we assign labels in the next step, no point gets assigned to that cluster. The algorithm proceeds and we end up with just 3 clusters instead of the desired 4. &lt;/p&gt;
&lt;p&gt;Consider an extreme example of this problem in 1-dimension. Suppose we have 10 evenly-sized tightly packed clusters of points concentrated at each of the odd integers from -9 to 9. If the data set is large, then when we randomly assign labels to each point, the resulting centroids are likely to be near 0. If the clusters are sufficiently tightly packed, then there will be a large interval between -1 and 1 containing no data points. In this situation, many of the clusters will disappear. &lt;/p&gt;
&lt;p&gt;We can try and avoid the problem of empty clusters at initialization by starting with centroids that are themselves data points. This is the idea of random points initialization and it means the clusters obtained from the initial centroids will not be empty. Unfortunately, for certain data configurations, it can still happen that a cluster becomes empty at a later point in the algorithm (an example can be found &lt;a href="http://user.ceng.metu.edu.tr/~tcan/ceng465_f1314/Schedule/KMeansEmpty.html"&gt;here&lt;/a&gt;), so any implementation of K-means should address this problem in some way.&lt;/p&gt;
&lt;p&gt;The random partition initialization method also has problems in the edge case when the number of clusters is large relative to the number of data points. For example, if we try to separate 1000 data points into 200 clusters, the random partition method will only yield the full 200 initial clusters just over 25 percent of the time. We can simulate this scenario in Python with the following block of code:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Set number of data points and clusters&lt;/span&gt;
&lt;span class="n"&gt;datapoints&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="n"&gt;clusters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;

&lt;span class="c1"&gt;# Perform a large number of trials&lt;/span&gt;
&lt;span class="n"&gt;trials&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;
&lt;span class="n"&gt;success&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trials&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Randomly assign labels&lt;/span&gt;
    &lt;span class="n"&gt;assignments&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clusters&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;datapoints&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Check whether all labels are present&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unique&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;assignments&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;clusters&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;success&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# Print the frequency of successful trials&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;success&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;trials&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Alternatively, as a fun little exercise you can calculate the exact probability using the inclusion-exclusion principle.&lt;/p&gt;
&lt;h2&gt;Random Points Initialization&lt;/h2&gt;
&lt;p&gt;In random points initialization we initialize the centroids rather than the labels. This is done by choosing K data points uniformly at random to be the initial centroids.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Random points initialization and first steps of K-means" src="https://yvanhuele.github.io/images/k-means/random_points_initialization.png" style="max-width:80%" /&gt;&lt;/p&gt;
&lt;p&gt;Because we're choosing the points uniformly at random, the initial centroids need not be very representative of the full data. In such cases, the algorithm can take a long time to converge or may converge to a poor clustering configuration. Below is an example an initialization that leads to a poor final clustering.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Random points initialization leading to sub-optimal clusters" src="https://yvanhuele.github.io/images/k-means/bad_random_points.png" style="max-width:80%" /&gt;&lt;/p&gt;
&lt;p&gt;Indeed, of the four clusters, only one seems to have been correctly isolated. The two clusters near the bottom have been combined into one large red cluster, while the cluster at the top has been split into two separate blue and orange clusters.&lt;/p&gt;
&lt;p&gt;One feature contributing to the poor clustering is the fact that the initial centroids were so close together. Having the initial centroids near each other doesn't necessarily mean we'll end up with a bad clustering, but it makes it more likely and often increases the number of steps that must be performed before the clusters settle down.&lt;/p&gt;
&lt;h2&gt;K-means++&lt;/h2&gt;
&lt;p&gt;The K-means++ initialization technique tries to avoid initial centroids that are close together.&lt;/p&gt;
&lt;p&gt;K-means++ is similar to random points initialization, in that it selects data points at random to act as the initial centroids. However, instead of choosing these points uniformly at random, K-means++ chooses them successively in such a way as to encourage the initial centroids to be spread out. Specifically, the probability that a point will be chosen as an initial centroid is proportional to the square of its distance to the existing initial centroids.&lt;/p&gt;
&lt;p&gt;Let's illustrate how this works with an example. To visualize the process more clearly, we'll work with a smaller dataset, consisting of only 20 data points separated into 4 clusters.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="K-means++ initialization" src="https://yvanhuele.github.io/images/k-means/plus_plus_initialization.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;When choosing the first centroid, all points are equally likely to be chosen. This is illustrated above by the fact that all the points in the first plot have the same hue. Once the first centroid is chosen, points farthest from this centroid are most likely to be chosen for the second centroid. Notice that in the third plot on the first row, the points in the upper left corner are darker and those in the bottom right are lighter. And, indeed, the point chosen as the second centroid is one of the ones in the top left. Once we have two centroids, the points in the center and center-left become darker, while those in the top-left become lighter.&lt;/p&gt;
&lt;p&gt;Notice that each of the initial centroids we chose is part of a different cluster. The probability of this occurring if the points are chosen uniformly at random is a little less than 13 percent (there are &lt;span class="math"&gt;\(20\)&lt;/span&gt; choose &lt;span class="math"&gt;\(4\)&lt;/span&gt; = &lt;span class="math"&gt;\(4845\)&lt;/span&gt; ways of choosing 4 points and &lt;span class="math"&gt;\(5^4 = 625\)&lt;/span&gt; ways of choosing one point from each cluster). Indeed, applying random points initialization on the same data with different random seeds gives the following initializations:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Random points initialization on small data set for five different seeds" src="https://yvanhuele.github.io/images/k-means/five_random_points.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;In none of these cases do we have exactly one initial centroid per cluster.&lt;/p&gt;
&lt;p&gt;Let's compare with &lt;span class="math"&gt;\(K\)&lt;/span&gt;-means++:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="K-means++ initialization on small data set for five different seeds" src="https://yvanhuele.github.io/images/k-means/five_kplusplus.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;Even though the initial centroids varied from one initialization to the next, we still ended up with one centroid per cluster.&lt;/p&gt;
&lt;p&gt;Having well separated initial centroids often causes the K-means clustering algorithm to converge more quickly. Of course, the K-means++ initialization procedure is more complicated, so there's a trade-off.&lt;/p&gt;
&lt;h2&gt;Comparing the Three Methods on our Toy Data&lt;/h2&gt;
&lt;p&gt;For each of the three methods, I ran 100 different random initializations and then carried out K-means clustering until the clusters stabilized. The results are plotted below (with a little jitter to show the frequency of different outcomes).&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Cluster quality and time to cluster for 100 runs of each of the three initialization techniques" src="https://yvanhuele.github.io/images/k-means/initialization_comparisons.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;Along the x-axis, we have the within-cluster variance, which is measure of the quality of the final clusters: tightly packed clusters have lower variance, spread-out clusters have higher variance. Along the y-axis, we have the number of steps following initialization before the clusters stabilize (where a step consists of either recomputing the centroids given the labels or recomputing the labels given the centroids). Points in the lower left of the graph correspond to good initializations (quickly converge to tight clusters) while those in the upper right correspond to poor initializations (slowly converge to spread-out clusters).&lt;/p&gt;
&lt;p&gt;The number of steps is a useful metric for gauging how well the algorithm performs once the initialization is complete, but does not reflect the complexity of the initialization. The points corresponding to K-means++ hug the lower left corner more closely than the other two initializations, but initializing K-means++ is also more complex. That being said, my experience working with data was that K-means++ was a little more efficient than the other two algorithms, taking roughly 60% as long to run completely (initialization all the way to stable clustering) as random points initialization (the slowest of the three).&lt;/p&gt;
&lt;p&gt;Finally, I want to emphasize that the within cluster variance varied between runs for all three initialization methods. Each method obtained the minimum possible within cluster variance and each method also yielded non-optimal final clusterings. Therefore, whatever initialization technique you use, it is important to run multiple random initializations. (In Scikit-Learn, the default setting is to run 10 random initializations and return the best output of the 10.)&lt;/p&gt;
&lt;h2&gt;What's Next?&lt;/h2&gt;
&lt;p&gt;In the next part of this series, we'll look more closely at how K-means minimizes the within cluster variance and look at data sets where minimizing this variance does not capture the underlying structure in the data. Some numeric data sets are just not well suited to K-means clustering. But sometimes data can be transformed to be more amenable to K-means through tricks like standardization. In part 3, we'll discuss these topics in more detail and illustrate them with example data sets.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="clustering"></category><category term="k-means"></category></entry><entry><title>Тооел</title><link href="https://yvanhuele.github.io/tooel.html" rel="alternate"></link><published>2018-03-26T18:00:00-06:00</published><updated>2018-03-26T18:00:00-06:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-03-26:/tooel.html</id><summary type="html">&lt;h2&gt;Stranger in a Not-So-Strange Land&lt;/h2&gt;
&lt;p&gt;I was recently on a plane for the first time in a while. When clouds obscured the landscape below, I decided to engage with the screen in front of me. Prompted to choose a language I opted for one I don't know all that well …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Stranger in a Not-So-Strange Land&lt;/h2&gt;
&lt;p&gt;I was recently on a plane for the first time in a while. When clouds obscured the landscape below, I decided to engage with the screen in front of me. Prompted to choose a language I opted for one I don't know all that well (as has been my habit) — this time I chose Russian. True to form, I quickly decided I was lost and scrambled to switch back into English. However, instead of giving up altogether, I spent a little time memorizing the screen and then switched back into Russian. Using my newfound knowledge of the screen layout, I was able to navigate to the in-flight map and explore the now-foreign landscape of the Western United States. I tested my reading skills with the transliterations of Salt Lake City (Солт-Лейк-Сити), Ogden (Огден), and Provo (Прово), but had to supress a laugh when I reached Tooele.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="In-flight map of Northern Utah" src="https://yvanhuele.github.io/images/wow/tooele.jpg" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;h2&gt;Defiantly Unphonetic&lt;/h2&gt;
&lt;p&gt;Tooele is the name of a city, county, and a valley in Northern Utah. The spelling is treacherous: Upon hearing the name &lt;em&gt;Tooele&lt;/em&gt; spoken out loud, you'd be forgiven for thinking it was spelled &lt;em&gt;Tuwilla&lt;/em&gt; instead. To add insult to injury, it &lt;a href="http://www.co.tooele.ut.us/clerk/information/tooele.pdf"&gt;seems the original spelling was Tuilla&lt;/a&gt;. Having tricked many people before, the unphonetic spelling certainly confused the Russian-language in-flight map, which offered the following transliteration: Тооел.&lt;/p&gt;
&lt;p&gt;Words with double o's are rare in Russian, but there are a few examples such as сообщение (message) and зоопарк (zoo). Using the pronunciation of these words as a guide, it would follow that Тооел should be pronounced &lt;em&gt;tah-ah-el&lt;/em&gt; or even &lt;em&gt;tah-ah-yel&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Russian Clash with the West&lt;/h2&gt;
&lt;p&gt;Being confused by Tooele is an understandable mistake. However, the in-flight map commits a more serious transgression by failing to be self-consistent. Indeed, just north of Тооел, we find the transliterations of West Jordan and West Valley City. These are rendered as Уэст-Джордан (&lt;em&gt;Oo-est Djor-dan&lt;/em&gt;) and Вест-Вэлли-Сити (&lt;em&gt;Vest-Veh-lee See-tee&lt;/em&gt;), respectively.&lt;/p&gt;
&lt;p&gt;Or perhaps the in-flight map is paying homage to &lt;a href="https://nameberry.com/blog/mormon-baby-names-traditions-and-trends"&gt;Utah's love of unconventional spellings&lt;/a&gt;.&lt;/p&gt;</content><category term="Russian"></category><category term="Cyrillic"></category><category term="Utah"></category><category term="fluff"></category></entry><entry><title>Exploring Style</title><link href="https://yvanhuele.github.io/exploring-style.html" rel="alternate"></link><published>2018-03-21T23:50:00-06:00</published><updated>2018-03-21T23:50:00-06:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-03-21:/exploring-style.html</id><summary type="html">&lt;h2&gt;Style Transfer&lt;/h2&gt;
&lt;p&gt;Recently, I've been having a lot of fun playing with &lt;a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb"&gt;this TensorFlow tutorial&lt;/a&gt; on style transfer by &lt;a href="http://www.hvass-labs.org/"&gt;Magnus Erik Hvass Pedersen&lt;/a&gt; based off of the paper &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf"&gt;&lt;em&gt;Image Style Transfer Using Convolutional Neural Networks&lt;/em&gt;&lt;/a&gt; by Gatys, Ecker, and Bethge. The basic goal in style transfer is to take an …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Style Transfer&lt;/h2&gt;
&lt;p&gt;Recently, I've been having a lot of fun playing with &lt;a href="https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb"&gt;this TensorFlow tutorial&lt;/a&gt; on style transfer by &lt;a href="http://www.hvass-labs.org/"&gt;Magnus Erik Hvass Pedersen&lt;/a&gt; based off of the paper &lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf"&gt;&lt;em&gt;Image Style Transfer Using Convolutional Neural Networks&lt;/em&gt;&lt;/a&gt; by Gatys, Ecker, and Bethge. The basic goal in style transfer is to take an image and redraw it in the artistic style of a separate image. The final result should match the content of the first image and the style of the second.&lt;/p&gt;
&lt;p&gt;For example, using the tutorial to combine a photograph of Delicate Arch with the style of &lt;a href="https://en.wikipedia.org/wiki/The_Hunters_in_the_Snow"&gt;Bruegel's Jagers in de Sneeuw&lt;/a&gt;, I obtained the following image:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="Delicate Arch in the style of juice from pitted cherries running down a wooden table" src="https://yvanhuele.github.io/images/style-transfer/arch+bruegel_jagers_full.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;Gatys, Ecker, and Bethge's suggested using a deep convolutional neural network to define both the content and the style of an image. The convolutional filters identify different features of an image: colors, corners, and edges in the early layers and more complicated features built from these in the later layers. Gatys, Ecker, and Bethge's idea was that these feature activations can be used to capture both content and style. &lt;/p&gt;
&lt;p&gt;The main goal of this post is to work towards a better understanding of what this algorithm is doing, especially what is meant by style and how it is captured. We'll approach this from a few different angles. In particular, we'll generate a few "pure style" images starting from photographs with strong stylistic features in order to get an idea of what does and what does not count towards style. All of the generated style images, along with the images they were based upon, can be found in the &lt;a href="https://github.com/yvanhuele/yvanhuele.github.io/tree/extra-blog-materials/exploring-style"&gt;blog materials Github repository&lt;/a&gt; (along with a few examples that didn't make it into this blog post).&lt;/p&gt;
&lt;p&gt;If you want to play with style transfer yourself but don't want to work directly with neural networks, you can make use of the algorithm in black-box fashion with &lt;a href="https://deepart.io/"&gt;DeepArt&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;What is Content?&lt;/h2&gt;
&lt;p&gt;Capturing content is fairly straightforward: if you can generate an image having the same feature activations as the original content image — that is, the images display the same shapes in the same locations — your two images should have similar content. Of course, if we match all of the feature activations perfectly, we risk reconstructing the content image too closely, thus defeating the purpose of style transfer. So we need to decide which layers of the convolutional network to use for content.&lt;/p&gt;
&lt;p&gt;One way to get an idea of what structure is captured by each layer of the network is to perform style transfer without a style image. That is, start with a white noise image and try and try to reconstruct our content image using only specific layers.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="Left: white noise; Right: image of Delicate Arch we wish to generate" src="https://yvanhuele.github.io/images/style-transfer/noise_to_arch.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;A perfect reconstruction would take the image on the left as input and produce the image on the right as output.&lt;/p&gt;
&lt;p&gt;We're working with the VGG-16 convolutional neural network described in &lt;a href="https://arxiv.org/abs/1409.1556"&gt;this paper&lt;/a&gt;. The network contains 13 convolutional layers using small (3x3) convolutional filters. Let's see what we get when we use different layers in the network for the content:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="Images of Delicate Arch generated using the different odd layers 1, 3, 5, ..., 13 as the content layer" src="https://yvanhuele.github.io/images/style-transfer/content_layers_arch.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;Matching the features at the first layer reproduces the image almost perfectly. By the thirteenth layer, the arch is almost unrecognizable. As we increase the layer we're working with, the colors match less and less and the edges become less sharp.&lt;/p&gt;
&lt;p&gt;Note that, when working with the earlier layers, we're not explicitly matching the complex features. Instead we get them for free by matching the smaller building blocks: if you know that you have two eyes sitting above a nose and a mouth, it's quite likely that you have a face.  &lt;/p&gt;
&lt;h2&gt;What is Style?&lt;/h2&gt;
&lt;p&gt;It might be tempting to try and capture style in the exact same way we did for content: try to match the features in the lower levels of the network to the style image. But we saw that matching the features in the low levels automatically matches the features in the high levels as well and we don't want to overwrite the content information. Furthermore, the feature activations themselves carry information about location and it's reasonable to expect style to be a global property of the image. Gatys, Ecker, and Bethge's idea was to not directly match the feature activations, but instead try to match some of their statistical properties. The tool they use for this is the &lt;a href="https://en.wikipedia.org/wiki/Gramian_matrix"&gt;Gram matrix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So what stylistic elements are captured by Gram matrices?&lt;/p&gt;
&lt;p&gt;We're going to explore this question both quantitatively and qualitatively. We'll begin with a highly simplified example — 2x2 black and white images — and work directly with Gram matrices to understand how they relate to style. Later on we'll use style transfer to generate images with style and no content. By comparing the original style images to the generated images, we can get a feeling as to what is counted as style when using the VGG-16 network.&lt;/p&gt;
&lt;p&gt;Put another way, we'll start with some math and then celebrate with some fun pictures.&lt;/p&gt;
&lt;h4&gt;Gram Matrix Definition&lt;/h4&gt;
&lt;p&gt;The Gram matrix of a set of vectors &lt;span class="math"&gt;\(v_1, v_2, \ldots, v_n\)&lt;/span&gt; is the matrix whose &lt;span class="math"&gt;\((i,j)\)&lt;/span&gt;-th entry consists of the dot product of &lt;span class="math"&gt;\(v_i\)&lt;/span&gt; with &lt;span class="math"&gt;\(v_j\)&lt;/span&gt;. If we let &lt;span class="math"&gt;\(V\)&lt;/span&gt; denote the matrix whose &lt;span class="math"&gt;\(j\)&lt;/span&gt;-th column is &lt;span class="math"&gt;\(v_j\)&lt;/span&gt;, so &lt;span class="math"&gt;\(V = [v_1 \; v_2 \; \cdots \; v_n]\)&lt;/span&gt;, then the Gram matrix of these vectors can be represented as the product &lt;span class="math"&gt;\(V^T V\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The Gram matrix is related to the covariance matrix: If the vectors are centered random variables (each entry of a fixed vector is drawn from the a common distribution with mean 0), then the Gram matrix is proportional to the sample covariance matrix. If the vectors are not centered, then the Gram matrix seems to capture a mix of information about both the means and the covariances.&lt;/p&gt;
&lt;p&gt;In both cases, the Gram matrix can be thought of as delocalizing the feature activation information. The Gram matrix captures some information about the feature activations, but it doesn't know in which part of the image these features are activated.&lt;/p&gt;
&lt;h3&gt;A Spherical Cow&lt;/h3&gt;
&lt;p&gt;&lt;img align="right" alt="2x2 image with white in top left corner and black everywhere else" src="https://yvanhuele.github.io/images/style-transfer/simple2x2.png" style="max-width:90%; margin:2%" /&gt;&lt;/p&gt;
&lt;p&gt;Let's work with a toy example. Like all &lt;a href="https://en.wikipedia.org/wiki/Spherical_cow"&gt;spherical cows&lt;/a&gt;, it has its limitations, but is a good place to start. Suppose we are working with 2x2 black and white images. We'll represent the intensity of each pixel on a scale from 0 (black) to 1 (white). We'll apply to each image a single 1x1 convolutional filter corresponding to the identity: it takes the pixel intensity as input and returns the same value as the output.&lt;/p&gt;
&lt;p&gt;For example, if we take the sample image on the right, the feature activations form the vector &lt;span class="math"&gt;\(v = [1, 0, 0, 0]\)&lt;/span&gt;. In this case, the Gram matrix has a single entry which is the dot product of this vector with itself:&lt;/p&gt;
&lt;div class="math"&gt;$$
1^2 + 0^2 + 0^2 + 0^2 = 1
$$&lt;/div&gt;
&lt;p&gt;Images with the same gram matrix can be represented by matrices &lt;span class="math"&gt;\(A = (a_{ij})\)&lt;/span&gt; satisfying&lt;/p&gt;
&lt;div class="math"&gt;$$
a_{11}^2 + a_{12}^2 + a_{21}^2 + a_{22}^2 = 1
$$&lt;/div&gt;
&lt;p&gt;Here are some examples of images satisfying this property:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="2x2 black and white images with the same Gram matrices" src="https://yvanhuele.github.io/images/style-transfer/same_gram.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;Both the mean and the variance of the pixel intensities vary from one image to the next with a sort of trade-off: as the mean intensity increases, the variance decreases.&lt;/p&gt;
&lt;p&gt;Covariance matrices are more familiar objects and more easily interpretable so let's see what we get when if we center the activations before computing the Gram matrix. The mean value of the coordinates of &lt;span class="math"&gt;\(v = [1, 0, 0, 0]\)&lt;/span&gt; is &lt;span class="math"&gt;\(1/4\)&lt;/span&gt;. Subtracting, we get the vector &lt;span class="math"&gt;\(w = [3/4, -1/4, -1/4, -1/4]\)&lt;/span&gt; and the dot product of &lt;span class="math"&gt;\(w\)&lt;/span&gt; with itself is&lt;/p&gt;
&lt;div class="math"&gt;$$
\left(\frac{3}{4}\right)^2 + \left(-\frac{1}{4}\right)^2 + \left(-\frac{1}{4}\right)^2 + \left(-\frac{1}{4}\right)^2 = \frac{3}{4}
$$&lt;/div&gt;
&lt;p&gt;For lack of a better term, we'll call this the &lt;em&gt;centered Gram matrix&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Each image with the same centered Gram matrix can be represented by a matrix of pixel intensities &lt;span class="math"&gt;\(A\)&lt;/span&gt; satisfying&lt;/p&gt;
&lt;div class="math"&gt;$$
(a_{11} - \bar{a})^2 + (a_{12} - \bar{a})^2 + (a_{21} - \bar{a})^2 + (a_{22} - \bar{a})^2 = \frac{3}{4}
$$&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\bar{a}\)&lt;/span&gt; is the mean of the entries:&lt;/p&gt;
&lt;div class="math"&gt;$$
\bar{a} = \frac{a_{11} + a_{12} + a_{21} + a_{22}}{4}
$$&lt;/div&gt;
&lt;p&gt;Here are some examples of images with this property:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="2x2 black and white images with the same centered Gram matrices" src="https://yvanhuele.github.io/images/style-transfer/same_centered.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;The pixel intensities of these images all have the same fixed variance of 3/4. However, the mean intensities do vary from one image to the next. So, for example, one could add or subtract 0.05 to each of the intensities in the third matrix without altering the centered Gram matrix.&lt;/p&gt;
&lt;p&gt;The Gram matrix and centered Gram matrix give different results. Which represents style better? It's difficult to say, especially with our constrained example. What happens if we impose both constraints? That is, what do we get if we require both the Gram matrix and the centered Gram matrix to match those of the original image?&lt;/p&gt;
&lt;p&gt;It turns out this is the same as fixing both the variance of the activations (and thus pixel intensities) and the activation means. We already know that the constraint on the centered Gram matrix fixes the variance. Recall that&lt;/p&gt;
&lt;div class="math"&gt;$$
\sum_{i,j} (a_{ij} - \bar{a})^2 = \sum_{i,j} a_{ij}^2 - 2 \bar{a} \sum_{i,j} a_{ij} + \sum_{i,j} \bar{a}^2 = \sum_{i,j} a_{ij}^2 - 4 \bar{a}^2
$$&lt;/div&gt;
&lt;p&gt;Using our constraints on the Gram matrix and centered Gram matrix, this reduces to
&lt;/p&gt;
&lt;div class="math"&gt;$$
\frac{3}{4} = 1 - 4 \bar{a}^2 \;\;\; \text{or} \;\;\; \bar{a}^2 = \frac{1}{16}
$$&lt;/div&gt;
&lt;p&gt;Because each of the &lt;span class="math"&gt;\(a_{ij}\)&lt;/span&gt; is nonnegative, it follows that &lt;span class="math"&gt;\(\bar{a} = 1/4\)&lt;/span&gt; or, equivalently, that the sum of the four activations is &lt;span class="math"&gt;\(1\)&lt;/span&gt;. It turns out that there are exactly four images satisfying these properties. To see this, consider our constraints:&lt;/p&gt;
&lt;div class="math"&gt;$$
\sum_{i, j} a_{ij}^2 = a_{11}^2 + a_{12}^2 + a_{21}^2 + a_{22}^2 = 1
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
\sum_{i, j} a_{ij} =  a_{11} + a_{12}  + a_{21} + a_{22} = 1
$$&lt;/div&gt;
&lt;p&gt;
and note that
&lt;/p&gt;
&lt;div class="math"&gt;$$
\left(\sum_{i, j} a_{ij} \right)^2 = \sum_{ij} a_{ij}^2 + 2 \left( \sum_{(i,j) \neq (k, \ell)} a_{ij} a_{k\ell} \right)
$$&lt;/div&gt;
&lt;p&gt;
Since &lt;span class="math"&gt;\(0 \leq a_{ij} \leq 1\)&lt;/span&gt;, it follows that each of the cross terms &lt;span class="math"&gt;\(a_{ij} a_{k\ell}\)&lt;/span&gt; is zero and, therefore, that at most one of the &lt;span class="math"&gt;\(a_{ij}\)&lt;/span&gt; is nonzero. The four images sharing these constraints are given below:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="2x2 black and white images with the same Gram matrices and centered Gram matrices" src="https://yvanhuele.github.io/images/style-transfer/same_gram_and_centered.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;To me, these appear to have the same style.&lt;/p&gt;
&lt;h4&gt;Further Exploration&lt;/h4&gt;
&lt;p&gt;I hope the example above was illuminating. We should be wary of drawing too strong of conclusions from such a simple example, but it seemed like a manageable place to start, and suggests some directions for further exploration. What if we work with 4x4 images and 2x2 filters? What if we use a different parametrization with black corresponding to -1 and use rectified linear activations? How should we measure the distance between styles when the Gram matrix is larger than 1x1?&lt;/p&gt;
&lt;p&gt;We won't pursue any of these ideas any further here. Instead I'll take the easy way out and leave their exploration as an exercise for the interested reader.&lt;/p&gt;
&lt;h3&gt;Visualizing Style&lt;/h3&gt;
&lt;p&gt;In the next part, we're going to try to understand style by using style transfer. Earlier, we tried generating Delicate Arch using a content image and no style. Now, we're going to generate images using only style and no content. The naming convention for the original images is a little haphazard (I didn't realize how far I would take this when I just got started and didn't feel like renaming them afterwards) but matches the file names in the &lt;a href="https://github.com/yvanhuele/yvanhuele.github.io/tree/extra-blog-materials/exploring-style"&gt;Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;The More Rigid Style&lt;/h4&gt;
&lt;p&gt;To capture style, instead of using the Gram matrix by itself, we'll use both the Gram matrix and the centered Gram matrix. Despite the discussion above, this decision was based more on trial-and-error than on theory. While playing around with style transfer and trying to understand what was going on, I replaced the Gram matrix with the centered Gram matrix. Often this improved the patterns in the generated image but messed up the colors. After experimenting a little, I decided to try and incorporate both matrices into my algorithm and suddenly the styles I was generating seemed a lot more accurate. I'll try and demonstrate this with some examples below.&lt;/p&gt;
&lt;p&gt;(An aside: When performing style transfer, you may be less interested in generating the most stylistically accurate image than in generating an aesthetically pleasing one. In that case, I would recommend experimenting a bit with how you choose to measure style.)&lt;/p&gt;
&lt;p&gt;Let's begin with a simple example: what is the style of a dark circle on a light background? In the figure below, the image on the left was used as the style image. The three other images were generated to match its style using just the regular Gram matrix, just the centered Gram matrix, and both Gram matrices, respectively.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles generated from a dark circle on a light background using Gram matrices, centered Gram matrices, and both" src="https://yvanhuele.github.io/images/style-transfer/style_comparison_circle.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;The image generated using the Gram matrix is mostly gray with a few concentration of light or dark points. The image generated using the centered Gram matrix does a better job of achieving the light and dark colors, but the balance is off: too many dark regions, not enough light regions. Using both matrices, we get a nice compromise: a good balance between light and dark, curved rather than straight edges, and mostly contiguous blobs.&lt;/p&gt;
&lt;p&gt;Let's look at some more examples.&lt;/p&gt;
&lt;p&gt;In some cases, the regular Gram matrix outperformed the centered Gram matrix. The colors are quite a bit off in the this muddy style generated using the centered matrix:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles generated from mud1 using Gram matrices, centered Gram matrices, and both" src="https://yvanhuele.github.io/images/style-transfer/style_comparison_mud1.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;In other cases, the centered Gram matrix outperformed the regular Gram matrix. The regular Gram matrix failed to capture the purple color of some of these peppers:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles generated from vegetables1 using Gram matrices, centered Gram matrices, and both" src="https://yvanhuele.github.io/images/style-transfer/style_comparison_vegetables1.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;And sometimes each captured different aspects of the style.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles generated from pinecone1 using Gram matrices, centered Gram matrices, and both" src="https://yvanhuele.github.io/images/style-transfer/style_comparison_pinecone1.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;But in all cases, at least to my eye, the images generated using a combination of both the regular Gram matrix and the centered Gram matrix most accurately captured the style of the original image they were based on.&lt;/p&gt;
&lt;p&gt;To incorporate both Gram matrices, I modified the gram_matrix function in the tutorial. The modified function I used is presented below:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gram_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_shape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# Get the number of feature channels for the input tensor, &lt;/span&gt;
    &lt;span class="c1"&gt;# which is assumed to be from a convolutional layer with 4-dim.&lt;/span&gt;
    &lt;span class="n"&gt;num_channels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;# Reshape the tensor so it is a 2-dim matrix. This essentially&lt;/span&gt;
    &lt;span class="c1"&gt;# flattens the contents of each feature-channel.&lt;/span&gt;
    &lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;# Subtract the mean activation value from each feature so that&lt;/span&gt;
    &lt;span class="c1"&gt;# our Gram matrix is proportional to the covariance matrix&lt;/span&gt;
    &lt;span class="n"&gt;means&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keepdims&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;centered_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;means&lt;/span&gt;

    &lt;span class="c1"&gt;# Calculate the Gram-matrix as the matrix-product of&lt;/span&gt;
    &lt;span class="c1"&gt;# the 2-dim matrix with itself. This calculates the&lt;/span&gt;
    &lt;span class="c1"&gt;# dot-products of all combinations of the feature-channels.&lt;/span&gt;
    &lt;span class="n"&gt;gram&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Do the same with the centered matrix&lt;/span&gt;
    &lt;span class="n"&gt;gram_centered&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;centered_matrix&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;centered_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Return both Gram matrices&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;gram&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gram_centered&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Different Style Layers&lt;/h4&gt;
&lt;p&gt;Just like content, the style of an image is different depending on which layers are considered. Let's start by working with the first layer of the convolutional network and add layers one by one.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="Style images generated from plants1 using an increasing number of layers" src="https://yvanhuele.github.io/images/style-transfer/style_layers_plants1.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;Using only the first layer seems to produce the right colors, but not much else. Adding the second layer, larger patches of matching colors begin to appear. When the third layer is added, little flame-like shapes begin to appear and these get larger and more leaf-like when the fourth and fifth layers are added into the mix. After the fifth or sixth layer, things don't seem to change much. This might be an optimization problem — maybe if we used a more sophisticated optimization technique and let our algorithm run longer, we'd get a different result — or it could just be that the effect of the higher layers is too subtle to notice.&lt;/p&gt;
&lt;p&gt;Since we tend to associate style with low level features (e.g. colors and edges), it makes sense to set an upper bound on which layers to use for style and include all of the layers below that. The style images generated in the previous section and those that we'll look at in the next section used all 13 layers of the network when considering style. Just to get an idea about the stylistic contribution of each individual layer, let's see what happens if we work with the layers one at a time.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img align="center" alt="Style images generated from plants1 using different individual layers" src="https://yvanhuele.github.io/images/style-transfer/style_layers_plants1bis.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;As we work with higher and higher layers, the patterns become more and more complex while the colors match those of the original image less and less.&lt;/p&gt;
&lt;h2&gt;Fashion Show&lt;/h2&gt;
&lt;p&gt;Now that we've decided how we're measuring style (using both the Gram matrix and centered Gram matrix for the feature activations from all 13 convolutional layers), we can try and understand style by looking at examples.&lt;/p&gt;
&lt;h4&gt;Contrived&lt;/h4&gt;
&lt;p&gt;Let's begin with some simple, contrived examples.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Style images generated from simple geometric patterns" src="https://yvanhuele.github.io/images/style-transfer/artificial_styles.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;The halves style image is mostly separated into large light and dark patches with long straight edges on the boundaries. With the checkers style, we get sharp corners, lots of straight vertical and horizontal edges, and a good balance of red and black. With the rainbow circles style, most of the edges are curved and the ordering of the colors is preserved (e.g. red patches are nested between orange and purple). The &lt;a href="https://www.lipsum.com/"&gt;lorem ipsum&lt;/a&gt; style doesn't contain any identifiable characters and the neat line spacing has been lost, but still displays many text-like properties.&lt;/p&gt;
&lt;h4&gt;Mostly Style&lt;/h4&gt;
&lt;p&gt;One way to understand style is to identify images that seem to be mostly style. Below are some examples where the generated style images closely resemble the images they're based on.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles that closely match the original image: algae1, barnacles2, cactus1, and cherry1" src="https://yvanhuele.github.io/images/style-transfer/faithful_styles1.png" style="max-width:90%" /&gt;
&lt;img alt="Styles that closely match the original image: fall_leaves1, flower5, moss1, and mud4" src="https://yvanhuele.github.io/images/style-transfer/faithful_styles2.png" style="max-width:90%" /&gt;
&lt;img alt="Styles that closely match the original image: needles1, petroglyphs1, rock1, and stones1" src="https://yvanhuele.github.io/images/style-transfer/faithful_styles3.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;We did lose a little bit of content (e.g. the crack between the barnacle covered rocks), but for the most part, the generated images could fill in for the originals if one doesn't look too closely. I think images generated using the style of mud 4 and rock 1 are particularly convincing.&lt;/p&gt;
&lt;h4&gt;Not Just Style&lt;/h4&gt;
&lt;p&gt;Conversely, we can look at images that have content in addition to style. You'd be unlikely to confuse the original images below with their associated generated style images.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles that don't closely match the original image: bighorn1, butterfly2, cactus3, redrock6" src="https://yvanhuele.github.io/images/style-transfer/content_styles1.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;Indeed, given only the generated images (those on the bottom row), you'd likely have a hard time determining what the original images (top row) might have been. It probably comes as no surprise that the photograph of the bighorn sheep is more than just style. Nevertheless, it's good to confirm our definition of style isn't too broad.&lt;/p&gt;
&lt;h4&gt;Flowers&lt;/h4&gt;
&lt;p&gt;Images of flowers provide a good case study of the balance between style and content. Even though they display many strong stylistic elements, individual flowers tend to contain more content (the arrangement of the petals and leaves, the position of the flower relative to the background), while images containing many of the same type of flowers together (flower 5 above and flower 17 below) are closer to pure style.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles for flower images 1, 4, 7, and 8" src="https://yvanhuele.github.io/images/style-transfer/flower_styles1.png" style="max-width:90%" /&gt;
&lt;img alt="Styles for flower images 10, 12, 13, and 17" src="https://yvanhuele.github.io/images/style-transfer/flower_styles2.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;p&gt;The flower images also highlight a common pattern of our algorithm: often the generated image pushes the bright color of the flower to the border of the image (e.g. flowers 7, 8, 10, and 12).&lt;/p&gt;
&lt;h4&gt;Surprises&lt;/h4&gt;
&lt;p&gt;Though I couldn't perfectly predict the appearance of the generated style images in advance, I found most of the results unsurprising. There were a few, however, that caught me off guard.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Styles from images with either more or less content than I expected: forest1, lilypad1, redrock2" src="https://yvanhuele.github.io/images/style-transfer/surprise_styles1.png" style="max-width:67.5%" /&gt;&lt;/p&gt;
&lt;p&gt;It seems the forest 1 and redrock 2 images contained more content than I thought. I was expecting to see straight dark tree trunks in the generated forest canopy. And I hadn't considered how important the location of the shadows is in the red rock image. The lilypad 1 image, on the other hand, seems to be less content and more style than I initially expected. In particular, the flowers in the generated image seem quite plausible.&lt;/p&gt;
&lt;h4&gt;Rogues Gallery&lt;/h4&gt;
&lt;p&gt;Thanks for reading! I hope that these examples have shed some light on what elements are treated as style for the purposes of style transfer (at least for the VGG-16 network). I had a lot of fun generating these images and I'll leave you with a few of my personal favorites:&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Original image and generated style for aspen1, books1, bridge1, and cat2" src="https://yvanhuele.github.io/images/style-transfer/favorite_styles1.png" style="max-width:90%" /&gt;
&lt;img alt="Original image and generated style for flamingo1, flower15, gasworks1, and lichen2" src="https://yvanhuele.github.io/images/style-transfer/favorite_styles2.png" style="max-width:90%" /&gt;
&lt;img alt="Original image and generated style for lilypad1, pie1, spiderweb1, and yucca2" src="https://yvanhuele.github.io/images/style-transfer/favorite_styles3.png" style="max-width:90%" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="style transfer"></category></entry><entry><title>Догадок</title><link href="https://yvanhuele.github.io/dogadok.html" rel="alternate"></link><published>2018-03-15T21:00:00-06:00</published><updated>2018-03-15T21:00:00-06:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-03-15:/dogadok.html</id><summary type="html">&lt;h2&gt;Some Guesswork&lt;/h2&gt;
&lt;p&gt;This week, we'll look at the Russian word &lt;em&gt;догадок&lt;/em&gt; (transliteration &lt;em&gt;dogadok&lt;/em&gt;), which, in the context we're interested in, means &lt;em&gt;conjectures&lt;/em&gt; or &lt;em&gt;guesswork&lt;/em&gt;. Our focus is really on the &lt;a href="https://en.wikipedia.org/wiki/Declension"&gt;declension&lt;/a&gt; of догадок (genitive plural) rather than its meaning: any Russian noun would do, but I chose that one because …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Some Guesswork&lt;/h2&gt;
&lt;p&gt;This week, we'll look at the Russian word &lt;em&gt;догадок&lt;/em&gt; (transliteration &lt;em&gt;dogadok&lt;/em&gt;), which, in the context we're interested in, means &lt;em&gt;conjectures&lt;/em&gt; or &lt;em&gt;guesswork&lt;/em&gt;. Our focus is really on the &lt;a href="https://en.wikipedia.org/wiki/Declension"&gt;declension&lt;/a&gt; of догадок (genitive plural) rather than its meaning: any Russian noun would do, but I chose that one because this post is based on a guess or  conjecture — or possibly just an inkling. Here is the (not very precise) conjecture: the declension of Russian nouns after numbers is related to the fact that the variance scales with the mean in count distributions.&lt;/p&gt;
&lt;h2&gt;Count Distributions&lt;/h2&gt;
&lt;p&gt;Richard McElreath brings up the relationship between the variance and the mean of a count distribution when introducing count models in his Winter 2015 &lt;a href="http://xcelab.net/rm/statistical-rethinking/"&gt;Statistical Rethinking&lt;/a&gt; lectures. He also describes how this relationship is reflected in human languages. The discussion relevant to this post begins &lt;a href="https://www.youtube.com/watch?v=BrchZeyo7cg&amp;amp;feature=youtu.be&amp;amp;t=1h7m10s"&gt;here&lt;/a&gt; and continues for just over a minute:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;"This is a very important thing about count variables. All count distributions are like this: the variance inflates with the mean. And that's true in nature as well: the bigger the magnitude of a count the more uncertainty there is around the mean and that's a normal thing about counts. This is actually kind of embedded intuitively in the inate human counting system which is logarithmic [...] it's present in all human languages: one, few, many. Right, that's logarithmic because it's magnitudes and people intuitively — even if they're not numerate beyond one, few, many — understand that many is vaguer than few and few is vaguer than one, so the precision goes down as [the mean] goes up as well."&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Numbers and Declension&lt;/h2&gt;
&lt;p&gt;This remark about one, few, and many got me thinking about &lt;a href="https://en.wikibooks.org/wiki/Russian/Numbers#Use_of_numerals_in_context"&gt;declension of nouns after numbers&lt;/a&gt; in Russian. The rules can get somewhat complex so I want to focus on the simplest example: counting objects.&lt;/p&gt;
&lt;h4&gt;The Basic Rule&lt;/h4&gt;
&lt;p&gt;We'll start with the following rule which is not quite correct and refine it later: &lt;em&gt;When there is exactly one of an object, use the nominative singular. When there are two, three, or four of an object, use the genitive singular. When there are five or more, use the genitive plural.&lt;/em&gt; (Note that we have different cases for one, few, and many.) For example, we have&lt;/p&gt;
&lt;p&gt;одна догадка (one guess, nominative singular)&lt;br /&gt;
две догадки (two guesses, genitive singular)&lt;br /&gt;
пять догадок (five guesses, genitive plural)&lt;/p&gt;
&lt;p&gt;"One guess, two guesses, five guesses" is a faithful translation, but if we were to try and force the grammar upon the English translation, it might take the form of "one guess, two [instances] of guess, five [instances] of guesses." It may help to see how the nominative and genitive cases are used in another context:&lt;/p&gt;
&lt;p&gt;Эта догадка такая же хорошая, как и любая другая. (This guess is as good as any other.)&lt;br /&gt;
Причина этой догадки неизвестна. (The reason for this conjecture is unknown.)&lt;br /&gt;
Случайность этих догадок поражает. (The randomness of these guesses is astounding.)  &lt;/p&gt;
&lt;p&gt;Both the form of the number preceding the noun and the &lt;a href="http://www.russianlessons.net/grammar/nouns_genitive.php"&gt;noun-ending&lt;/a&gt; itself depend on the gender of the noun, but the pattern of nominative singular, genitive singular, genitive plural is followed across all genders:&lt;/p&gt;
&lt;p&gt;один суп (one soup)&lt;br /&gt;
два супа (two soups)&lt;br /&gt;
пять супов (five soups)&lt;/p&gt;
&lt;p&gt;одна ворона (one crow)&lt;br /&gt;
две вороны (two crows)&lt;br /&gt;
пять ворон (five crows)  &lt;/p&gt;
&lt;p&gt;одно слово (one word)&lt;br /&gt;
два слова (two words)&lt;br /&gt;
пять слов (five words)  &lt;/p&gt;
&lt;h4&gt;The Catch&lt;/h4&gt;
&lt;p&gt;So far so good, we seem to have different rules for one, few (two, three, four), and many (five or more). However, rule described above only works as long as the objects number twenty or fewer. As soon as we hit twenty-one, we start over. Numbers ending in one (but not in eleven) take us back to the nominative singular:&lt;/p&gt;
&lt;p&gt;одна догадка (one guess)&lt;br /&gt;
двадцать одна догадка (twenty-one guesses)&lt;br /&gt;
сто девяносто одна догадка (one hundred ninety-one guesses)&lt;/p&gt;
&lt;p&gt;Similarly, numbers ending in two, three, or four (but not in twelve, thirteen, or fourteen) are followed by nouns in the genitive singular. For all others, we're back at the genitive plural.&lt;/p&gt;
&lt;p&gt;So, now that we know the full rule, is the conjecture still valid? Your guess is as good as mine.&lt;/p&gt;</content><category term="Russian"></category><category term="grammar"></category></entry><entry><title>Ворона</title><link href="https://yvanhuele.github.io/vorona.html" rel="alternate"></link><published>2018-03-08T13:00:00-07:00</published><updated>2018-03-08T13:00:00-07:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-03-08:/vorona.html</id><summary type="html">&lt;p&gt;This week, our featured word is ворона, or maybe it's собака, or maybe it's корова, or maybe it's all three. These are the Russian words for crow, dog, and cow, respectively.&lt;/p&gt;
&lt;p&gt;They figure in a short Soviet claymation film, Пластилиновая ворона (&lt;a href="https://en.wikipedia.org/wiki/Plasticine_Crow"&gt;Plasticine Crow&lt;/a&gt;), based on Aesop's fable about the fox …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week, our featured word is ворона, or maybe it's собака, or maybe it's корова, or maybe it's all three. These are the Russian words for crow, dog, and cow, respectively.&lt;/p&gt;
&lt;p&gt;They figure in a short Soviet claymation film, Пластилиновая ворона (&lt;a href="https://en.wikipedia.org/wiki/Plasticine_Crow"&gt;Plasticine Crow&lt;/a&gt;), based on Aesop's fable about the fox and the crow. The narrator is uncertain about the details of the story so we are presented with multiple possiblities from the time of day, to the size of the cheese, to the identities of the main characters. Is it a crow or perhaps a dog or a cow? Is it a fox or is it instead a janitor/street-sweeper?&lt;/p&gt;
&lt;p&gt;The video is available &lt;a href="https://youtu.be/WVb_MKlsi1s"&gt;here on youtube&lt;/a&gt; and an English translation can be found &lt;a href="http://lyricstranslate.com/ru/mozhet-buit-vorona-%D0%B0-%D0%BC%D0%BE%D0%B6%D0%B5%D1%82-%D0%B1%D1%8B%D1%82%D1%8C-%D0%B2%D0%BE%D1%80%D0%BE%D0%BD%D0%B0-and-probably-crow.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="stylized images of crows, a dog, and a cow" src="https://yvanhuele.github.io/images/wow/mozhet_byt.jpg" style="max-width:90%" /&gt;
&lt;br&gt;
&lt;em style="font-size:90%"&gt;может быть ворона, а может быть собака, а может быть корова/ maybe a crow, or maybe a dog, or maybe a cow&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For me as a language learner, the cartoon strikes a good balance between structure and whimsy. You often get similar concepts together: the cheese might have been 200 grams, 300 grams, or half a kilo and might have been denstined for breakfast, lunch, or dinner. Presented together the relationships between these concepts are reinforced. 
On the other hand, the story sometimes takes you by surprise and introduces you to phrases you probably wouldn't encounter in other contexts: The fox might be an evil ostrich! And the moral of the story — not to horse around on construction sites — is an interesting alternative to the one presented in &lt;a href="https://en.wikipedia.org/wiki/La_Fontaine%27s_Fables"&gt;La Fontaine's version&lt;/a&gt; about the perils of being taken in by flattery. La Fontaine's version can be found translated into English &lt;a href="https://books.google.com/books?id=JW5bAAAAQAAJ&amp;amp;dq=Fables%20%20Denis&amp;amp;pg=PA83#v=onepage&amp;amp;q&amp;amp;f=false"&gt;here&lt;/a&gt; or set to music and performed live by Les Frères Jacques &lt;a href="https://youtu.be/d6Xp_uzxpeQ"&gt;here&lt;/a&gt;. Though, &lt;a href="https://en.wikipedia.org/wiki/The_Fox_and_the_Crow_(Aesop)#The_story"&gt;apparently&lt;/a&gt; La Fontaine's moral was not always viewed as sufficiently moralizing by some who were scandalized that the fox was allowed to make off with his ill-gotten cheese.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="stylized cat" src="https://yvanhuele.github.io/images/wow/koshka.png" style="max-width:30%" /&gt;
&lt;br&gt;
&lt;em style="font-size:90%"&gt;a new possibility for your consideration: а может быть это кошка&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Sneak Preview&lt;/h3&gt;
&lt;p&gt;The images in this post offer a taste of an upcoming blog post. They were made using a style transfer algorithm to render photographs in the style of one of the frames from the Plasticine Crow.&lt;/p&gt;</content><category term="Russian"></category><category term="cartoons"></category></entry><entry><title>Winkelwagen</title><link href="https://yvanhuele.github.io/winkelwagen.html" rel="alternate"></link><published>2018-02-25T20:00:00-07:00</published><updated>2018-02-25T20:00:00-07:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-02-25:/winkelwagen.html</id><summary type="html">&lt;h2&gt;What's Your Angle?&lt;/h2&gt;
&lt;p&gt;This week's word is the Dutch &lt;em&gt;winkelwagen&lt;/em&gt;: &lt;em&gt;winkel&lt;/em&gt; means shop or store, &lt;em&gt;wagen&lt;/em&gt; means cart or car, and together they form a shopping cart. I found the sound of the word amusing and wanted to feature it for that reason alone.&lt;/p&gt;
&lt;p&gt;I was just going to leave …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;What's Your Angle?&lt;/h2&gt;
&lt;p&gt;This week's word is the Dutch &lt;em&gt;winkelwagen&lt;/em&gt;: &lt;em&gt;winkel&lt;/em&gt; means shop or store, &lt;em&gt;wagen&lt;/em&gt; means cart or car, and together they form a shopping cart. I found the sound of the word amusing and wanted to feature it for that reason alone.&lt;/p&gt;
&lt;p&gt;I was just going to leave it at that when I began to wonder about the word &lt;em&gt;winkel&lt;/em&gt;: The Ducth word for shop didn't seem to match any word for shop that I knew in other languages. To be fair, unlike the word market (Dutch: &lt;em&gt;markt&lt;/em&gt;; German: &lt;em&gt;Markt&lt;/em&gt;; French: &lt;em&gt;marché&lt;/em&gt;; Spanish: &lt;em&gt;mercado&lt;/em&gt;), the words for shop or store seem to vary a lot by language (German: &lt;em&gt;Geschäft&lt;/em&gt;, &lt;em&gt;Laden&lt;/em&gt;; French: &lt;em&gt;magazin&lt;/em&gt;, &lt;em&gt;boutique&lt;/em&gt;; Spanish: &lt;em&gt;tienda&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Digging deeper, I learned that winkel &lt;a href="https://en.wiktionary.org/wiki/winkel#Etymology"&gt;once meant corner&lt;/a&gt;. Had I done any mathematics in German, I might have known that &lt;em&gt;Winkel&lt;/em&gt; is the German word for angle. Anyways, it seems that corner turned into corner store, then into store and lost its original meaning of corner (&lt;em&gt;hoek&lt;/em&gt; in modern Dutch).&lt;/p&gt;
&lt;h2&gt;Periwinkle Periwinkles&lt;/h2&gt;
&lt;p&gt;Winkel shares a common root with the English words &lt;em&gt;winch&lt;/em&gt; and &lt;em&gt;wink&lt;/em&gt;.  These words also share a common root with one type of &lt;em&gt;periwinkle&lt;/em&gt;, but not with its homonym. We can split periwinkles into two categories: in one category is a &lt;a href="https://en.wikipedia.org/wiki/Common_periwinkle"&gt;type of snail&lt;/a&gt; and in the other is a &lt;a href="https://en.wikipedia.org/wiki/Vinca"&gt;type of flower&lt;/a&gt; along with a &lt;a href="https://en.wikipedia.org/wiki/Periwinkle_(color)"&gt;color&lt;/a&gt; matching that of the flower. The snail is &lt;a href="https://en.wiktionary.org/wiki/periwinkle#Etymology_2"&gt;related&lt;/a&gt; to winking, but the flower &lt;a href="https://en.wiktionary.org/wiki/periwinkle#Etymology_1"&gt;is not&lt;/a&gt;.&lt;/p&gt;</content><category term="Dutch"></category><category term="etymology"></category></entry><entry><title>K-Means Clustering Part 1</title><link href="https://yvanhuele.github.io/k-means-clustering-part-1.html" rel="alternate"></link><published>2018-02-18T18:00:00-07:00</published><updated>2018-02-18T18:00:00-07:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-02-18:/k-means-clustering-part-1.html</id><summary type="html">&lt;h2&gt;Just Another Review of K-Means&lt;/h2&gt;
&lt;p&gt;K-means clustering is a well-known algorithm for which there already exist many good online resources. My first introduction to K-means (as was the case with many other machine learning techniques) was from the textbook &lt;a href="http://www-bcf.usc.edu/~gareth/ISL/"&gt;&lt;em&gt;Introduction to Statistical Learning&lt;/em&gt;&lt;/a&gt;. However, a recent experience caused me to …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Just Another Review of K-Means&lt;/h2&gt;
&lt;p&gt;K-means clustering is a well-known algorithm for which there already exist many good online resources. My first introduction to K-means (as was the case with many other machine learning techniques) was from the textbook &lt;a href="http://www-bcf.usc.edu/~gareth/ISL/"&gt;&lt;em&gt;Introduction to Statistical Learning&lt;/em&gt;&lt;/a&gt;. However, a recent experience caused me to revisit this algorithm. After discussing K-means with someone who held some misconceptions about the algorithm, I decided to dig deeper into some of the details. Though I doubt those misconceptions are widely held, I wanted to address a few of them. Looking more closely at the algorithm, I learned a few new things as well -- in particular, the different initialization techniques. Instead of focusing on a few isolated aspects of K-means, it seemed more natural to wrap them together into a general discussion of the algorithm. And that's how another review of K-means clustering was born.  I wish I could say that I'm presenting K-means from an exciting new point of view that will completely redefine the way you think about the algorithm. But the truth is I mostly just had fun making some plots and wanted to share the results.&lt;/p&gt;
&lt;p&gt;I decided to split the discussion into several posts. In this first post, we'll talk about why one might use K-means clustering, discuss how to choose the number of clusters, and then give a brief overview of the algorithm. In the &lt;a href="http://www.salientiastuff.com/k-means-clustering-part-2.html"&gt;second part&lt;/a&gt;, we'll discuss different initialization techniques and the importance of running the algorithm several times with different random initializations. Then, in a third post, we'll look a little more closely at the math behind K-means and look at some data that causes trouble for K-means.&lt;/p&gt;
&lt;p&gt;The figures in this post were generated using Matplotib. All of the code can be found in &lt;a href="https://github.com/yvanhuele/yvanhuele.github.io/blob/extra-blog-materials/K-Means/K-Means%20Clustering.ipynb"&gt;this jupyter notebook&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;K-Means at a Glance&lt;/h2&gt;
&lt;p&gt;K-means clustering is an unsupervised learning algorithm which separates data into K distinct groups. As with many other unsupervised methods, the goal is to discover hidden structure within the data. In particular, K-means tries to separate data points into groups where the points in a group are closer to each other than to points in other groups.&lt;/p&gt;
&lt;p&gt;In low dimensional data (2 or 3 variables), we might be able to directly identify structure by plotting the data. For higher dimensional data, this cannot often be done nicely. Furthermore, even when we can identify structure in data by plotting it, we often want to describe the structure in a way that we can make further use of it.&lt;/p&gt;
&lt;p&gt;For example, in the plot below, we can see that the points cluster nicely into four distinct blobs, but if we want to make use of this clustering, we need a criterion for determining which points are part of each cluster.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Four well-separated clusters of points" src="https://yvanhuele.github.io/images/k-means/four_blobs.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;We might start by noting that the points in the top-left cluster are distinguished from the rest by the property that &lt;span class="math"&gt;\(x &amp;lt; 0\)&lt;/span&gt; and &lt;span class="math"&gt;\(y &amp;gt; 6\)&lt;/span&gt;. Similar methods work for the bottom-right cluster, but the &lt;span class="math"&gt;\(x\)&lt;/span&gt;- and &lt;span class="math"&gt;\(y\)&lt;/span&gt;-coordinates of the two other clusters overlap.&lt;/p&gt;
&lt;p&gt;Thus, we turn to unsupervised learning techniques such as K-means clustering to discover structure in our data.&lt;/p&gt;
&lt;h2&gt;An Application&lt;/h2&gt;
&lt;p&gt;A common application of clustering techniques is &lt;a href="https://en.wikipedia.org/wiki/Market_segmentation"&gt;market segmentation&lt;/a&gt;. If an online shopping site has access to information about its customers such as browsing history, purchasing history, age, geographic location, it can be useful to separate its customer base into different subgroups. The purpose of clustering can simply be descriptive — to get an idea of the customer base. For example, suppose the site's customers are predominantly either college students in New England or retirees in Arizona. Looking at the average customer over the whole data set is not very helpful since, in reality, the site has few middle aged customers from Missouri. On the other hand, if the site's customers are first split into two subgroups, the average attributes of each subgroup would be more enligtening. Clustering can also be used to help in supervised learning problems. The site is unlikely to have a huge amount of purchasing data for every single one of its customers. By grouping together similar customers, the site can leverage a lot more data to determine which products a given customer is likely to buy and can target its advertisements accordingly.&lt;/p&gt;
&lt;p&gt;Some other applications of K-means are listed &lt;a href="https://en.wikipedia.org/wiki/K-means_clustering#Applications"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;An Example: Handwritten Digits&lt;/h2&gt;
&lt;p&gt;We're going to illustrate the power of K-means through a toy problem, by looking at images of handwritten digits. Specifically, we'll work with the test set of the &lt;a href="http://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits"&gt;UCI ML Optical Recognition of Handwritten Digits Data Set&lt;/a&gt; which is included in the &lt;a href="http://scikit-learn.org/stable/datasets/index.html"&gt;scikit-learn datasets package&lt;/a&gt;. This data set consists of 1797 samples, each corresponding to the pixel intensities of an 8 by 8 pixel grayscale image of a handwritten digit. A few example images are shown below (reconstructed from 8x8 numeric arrays of pixel intensities):&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Examples of handwritten digits from the dataset" src="https://yvanhuele.github.io/images/k-means/example_digits.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Toy Problem:&lt;/strong&gt; &lt;em&gt;Separate the digits into 3 groups of digits having similar shapes (or, more precisely, similar pixel intensity values).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We already have a good system for separating these digits into 10 classes (i.e., by digit), but it's not quite as clear how to separate them into just 3 classes. To try and solve this problem, we can apply K-means clustering with &lt;span class="math"&gt;\(K = 3\)&lt;/span&gt;, and look at some of the digits that made it into each cluster.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Digits separated into three clusters" src="https://yvanhuele.github.io/images/k-means/digit_clusters.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;Without knowing anything about digits, the algorithm has nonetheless picked up on similarities. For example, the last cluster seems to contain most of the 0s, 4s, and 6s.&lt;/p&gt;
&lt;p&gt;For a more rigorous analysis, consider the following table which records how many instances of each digit made it into each cluster.&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{array}{r|rrrrrrrrrr}
 &amp;amp; 0 &amp;amp; 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 &amp;amp; 5 &amp;amp; 6 &amp;amp; 7 &amp;amp; 8 &amp;amp; 9 \\ \hline
1 &amp;amp; 2 &amp;amp; 38 &amp;amp; 161 &amp;amp; 167 &amp;amp; 0 &amp;amp; 72 &amp;amp; 1 &amp;amp; 0 &amp;amp; 65 &amp;amp; 146 \\
2 &amp;amp; 0 &amp;amp; 140 &amp;amp; 16 &amp;amp; 16 &amp;amp; 55 &amp;amp; 97 &amp;amp; 1 &amp;amp; 179 &amp;amp; 108 &amp;amp; 34 \\
3 &amp;amp; 176 &amp;amp; 4 &amp;amp; 0 &amp;amp; 0 &amp;amp; 126 &amp;amp; 13 &amp;amp; 179 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
\end{array}
$$&lt;/div&gt;
&lt;p&gt;We see that cluster 1 contains most of the 2s, 3s, and 9s, that cluster 2 contains most of the 1s and 7s, and cluster 3 contains most of the 0s, 4s, and 6s and that the 5s and 8s are mostly split between clusters 1 and 2. Another way to see how the clusters split up the data is to use &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;principal component analysis&lt;/a&gt; (PCA), a method for representing high-dimensional data in 2-dimensions in such a way as to preserve as much spread as possible.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Clustered digits plotted with the first 2 principal components" src="https://yvanhuele.github.io/images/k-means/digits_pca.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;h2&gt;Restrictions&lt;/h2&gt;
&lt;p&gt;K-means clustering cannot be applied to all data sets, and even when it can be applied, it may not give great results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, the &lt;strong&gt;data must be numerical&lt;/strong&gt;: we need to be able to compute distances between data points and to average data points. There are alternative clustering methods that can deal with categorical or mixed data types, such as K-modes or K-medoids with the &lt;a href="https://stats.stackexchange.com/a/15313"&gt;Gower metric&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The number of clusters K must be set in advance.&lt;/strong&gt; That is, K-means clustering cannot pick the number of clusters for you. We'll talk about this more in the next section.&lt;/li&gt;
&lt;li&gt;The goal of K-means is to minimize the distances between points in the same cluster. This captures a specific type of structure, but fails to capture other patterns, and &lt;strong&gt;there are numerical data sets that are not well-suited to K-means&lt;/strong&gt;. We'll discuss this in more detail in a later blog post.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;What is K?&lt;/h2&gt;
&lt;p&gt;The number of clusters, K, is a hyperparameter that must be set in advance. Often, K is chosen using domain expertise. You can also often get an idea for the number of clusters through plotting and data exploration.&lt;/p&gt;
&lt;p&gt;Let's explore this further using a real-world data set: &lt;a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;Fisher's Iris dataset&lt;/a&gt;. The Iris data set one of many included in &lt;a href="http://scikit-learn.org/stable/datasets/index.html"&gt;scikit-learn's datasets package&lt;/a&gt;. The Iris data set contains 150 sets of measurements for 3 different species of Iris (50 samples from each species)&lt;/p&gt;
&lt;p&gt;One way to examine the data by plotting each variable against every other variable using a &lt;a href="https://seaborn.pydata.org/generated/seaborn.pairplot.html"&gt;pairplot&lt;/a&gt; from the seaborn library.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Pair plot of Iris data without species labels" src="https://yvanhuele.github.io/images/k-means/iris_pairplot_unlabeled.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at these plots, we do indeed see some underlying structure. The five pair plots along with the histogram for petal length separate the data into two distinct groups. Recall though that there should be 3 different species of iris represented. What's going on?&lt;/p&gt;
&lt;p&gt;Since we have the luxury of knowing the individual labels (i.e. which iris species each point corresponds to), let's go ahead a look at these plots again after incorporating this information.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Pair plot of Iris data with species labels" src="https://yvanhuele.github.io/images/k-means/iris_pairplot_labeled.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;We see that the data do indeed cluster into three groups, but that two of those just barely overlap.&lt;/p&gt;
&lt;p&gt;Another way of plotting high dimensional data is to use a dimensionality reduction technique such as PCA.  Below, the Iris data set is plotted using the first two principal components.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Iris data plotted using 2 principal components" src="https://yvanhuele.github.io/images/k-means/iris_PCA.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;So, by exploring the data through visualizations and by using domain expertise, we have come up with two reasonable values of K, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(K = 2\)&lt;/span&gt; seems most natural based on the various plots of the data.&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(K = 3\)&lt;/span&gt; would be an obvious choice if you knew that the data set contained specimens from three different species, but didn't have the species labels included in the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The results of performing K-means clustering with &lt;span class="math"&gt;\(K = 2\)&lt;/span&gt; and &lt;span class="math"&gt;\(K = 3\)&lt;/span&gt; are presented below.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="K-means clustering on Iris data with K = 2 and K = 3" src="https://yvanhuele.github.io/images/k-means/iris_clustering.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;Note that neither one of these solutions perfectly separates the data (either into the 3 distinct species or into setosa/non-setosa), but they come pretty close. &lt;/p&gt;
&lt;p&gt;In the absence of domain-expertise, there are a &lt;a href="https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set"&gt;variety of methods&lt;/a&gt; one can use to select the number of clusters.&lt;/p&gt;
&lt;h2&gt;A Look at the Algorithm&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;For a fine algorithm that gleans&lt;br /&gt;
Hidden groupings: two, four, maybe teens&lt;br /&gt;
Build centroid and label&lt;br /&gt;
Keep up 'til it's stable&lt;br /&gt;
That's a very rough draft of K-means&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;K-means clustering is performed by iterating two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use the cluster labels to recompute the &lt;a href="https://en.wikipedia.org/wiki/Centroid"&gt;cluster centroids&lt;/a&gt; (geometric centers).&lt;/li&gt;
&lt;li&gt;Use the cluster centroids to recompute the cluster labels.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each iteration of these steps reduces the within-cluster variation (i.e. readjusts the clusters so that they're more compact) and, eventually, the clusters will settle down to a stable configuration: neither the labels nor the centroids will change. A few steps of this process are illustrated in the figure below (using &lt;span class="math"&gt;\(K = 4\)&lt;/span&gt;):
Let's wrap up this section with small warning: the number of clusters is an optional parameter in the scikit-learn &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"&gt;KMeans&lt;/a&gt; function. However, this implementation is not cleverly selecting the number of clusters based on properties of the data. Instead it's just using the fixed default value of 8 clusters.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="a few clustering steps" src="https://yvanhuele.github.io/images/k-means/clustering_process.png" style="max-width:100%" /&gt;&lt;/p&gt;
&lt;p&gt;On the far left, we start with cluster labels (represented by the colors) which we use to compute the centroids in the second figure which are denoted by stars. This illustrates step 1. Now, notice that the labels don't seem well matched to the centroids: for example, the blue point near (0, 5) is much closer to the red centroid than the blue one.&lt;/p&gt;
&lt;p&gt;So, going from the second figure to the third, we apply step 2 and relabel each data point so that it matches the nearest centroid. Now the labels give us better looking clusters, but the old centroids are no longer centrally located. The orange star in the third figure is too far to the right; the blue star is too low. We can fix this by applying step 1 again to get the figure on the far right.&lt;/p&gt;
&lt;p&gt;In this example, further repetition of these steps won't change anything: we've achieved a stable clustering. However, in general you might need to apply steps 1 and 2 many times before getting your final clusters (and we'll see examples of this later on).&lt;/p&gt;
&lt;h2&gt;What's Next?&lt;/h2&gt;
&lt;p&gt;You may have noticed a problem with the description of K-means clustering given above: To perform step 1, we need to already have cluster labels. We can get labels from step 2, but only if we already have cluster centroids. Thus, before iterating these steps, we need to either initialize labels or initialize centroids.&lt;/p&gt;
&lt;p&gt;There are various methods for initializing the labels or the centroids. The reason you might want to consider different initialization techniques is because, even though K-means is guaranteed to converge to a stable clustering, the clustering might not be optimal. That is, different initializations can lead to different outcomes. To avoid having to restart too many times, we want initialize in a clever way. In &lt;a href="http://www.salientiastuff.com/k-means-clustering-part-2.html"&gt;part 2&lt;/a&gt; of this series, we'll discuss several initialization methods and discuss the importance of multiple random initializations in more detail.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="clustering"></category><category term="k-means"></category></entry><entry><title>Суп</title><link href="https://yvanhuele.github.io/sup.html" rel="alternate"></link><published>2018-02-18T17:30:00-07:00</published><updated>2018-02-18T17:30:00-07:00</updated><author><name>Yannick</name></author><id>tag:yvanhuele.github.io,2018-02-18:/sup.html</id><summary type="html">&lt;h2&gt;Big Cottonwood Soup&lt;/h2&gt;
&lt;p&gt;Last week, I experienced a bit of reverse culture shock. This was all the more surprising given that I had neither left my original cultural environment nor spent any significant amount of time emerged in the culture I had seemingly adopted.&lt;/p&gt;
&lt;p&gt;I was waiting for the ski …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Big Cottonwood Soup&lt;/h2&gt;
&lt;p&gt;Last week, I experienced a bit of reverse culture shock. This was all the more surprising given that I had neither left my original cultural environment nor spent any significant amount of time emerged in the culture I had seemingly adopted.&lt;/p&gt;
&lt;p&gt;I was waiting for the ski bus and looking over the posted schedule.  After checking the return times, my eyes were drawn to the route map. Upon reading the labels &lt;em&gt;Big Cottonwood Cyn&lt;/em&gt; and &lt;em&gt;Little Cottonwood Cyn&lt;/em&gt;, I did a double-take:  It took me a full ten seconds to realize that &lt;em&gt;cyn&lt;/em&gt; is the (English) abbreviation for canyon rather than &lt;em&gt;суп&lt;/em&gt;, the Russian word for soup. With italics, they're indistinguishable, so here they are again without emphasis: cyn vs суп. Despite the small difference, having once misread the sign, I cannot unsee the soup.&lt;/p&gt;
&lt;p align="center"&gt;&lt;img alt="Cyn abbreviations in UTA ski bus map and Russian Wikipedia article on суп" src="https://yvanhuele.github.io/images/wow/cyn.png" style="max-width:90%" /&gt;
&lt;br&gt;
&lt;em style="font-size:90%"&gt;Left: &lt;a href="https://www.rideuta.com/-/media/Files/Rider-Tools/System-Maps/2017/2017_skimap_justmap.ashx?la=en"&gt;UTA ski bus map&lt;/a&gt;. Right &lt;a href="https://ru.wikipedia.org/wiki/%D0%A1%D1%83%D0%BF"&gt;Russian Wikipedia article on soup&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;The Opposite Problem&lt;/h2&gt;
&lt;p&gt;Although this is the first time I've accidentally mistaken the Latin alphabet for Cyrillic, the opposite problem — reading Cyrillic characters as Latin ones — was very common when I first started learning Russian and Ukrainian and is a problem that continues to haunt me.  Many &lt;a href="https://en.wikipedia.org/wiki/Cyrillic_alphabets#Common_letters"&gt;Cyrillic letters&lt;/a&gt; look the same as Latin letters but are pronounced differently. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;В/в sounds like V/v&lt;/li&gt;
&lt;li&gt;Н/н sounds like N/n&lt;/li&gt;
&lt;li&gt;Р/р sounds like R/r&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One of the more infamous examples is &lt;a href="https://en.wiktionary.org/wiki/pectopah"&gt;ресторан&lt;/a&gt; (restaurant, transliteration: &lt;em&gt;restoran&lt;/em&gt;), but others include север (north, transliteration: &lt;em&gt;sever&lt;/em&gt;), верх (up, transliteration: &lt;em&gt;verkh&lt;/em&gt;), and of course the СССР (USSR, which is surprisingly close to the transliteration: &lt;em&gt;SSSR&lt;/em&gt;).&lt;/p&gt;</content><category term="Russian"></category><category term="Cyrillic"></category></entry></feed>